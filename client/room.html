<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Build a Thing Video App</title>
    <style>
      .content {
        display: none;
      }
      .content.opened{
        display: block;
      }
    </style>
  </head>
  <body>
    <div class="preferences">
      <button>Open</button>
      <div class="processing content">
        <video autoplay style="display: none;"></video>
        <canvas></canvas>
        <canvas style="display: none;"></canvas>
        <form id="background-image-form" autocomplete="off" style="display: grid; grid-template-columns: auto auto;">
          <label for="image-input">Background Image</label>
          <span>
            <input id="image-input" type="file" />
            <button id="remove-image" type="button">Clear</button>
          </span>

          <label for="overlay-input">Overlay</label>
          <input id="overlay-input" type="checkbox" />

          <label for="x-input">X</label>
          <input id="x-input" type="number" step="1" value="0" disabled />

          <label for="y-input">Y</label>
          <input id="y-input" type="number" step="1" value="0" disabled />

          <label for="width-input">Width</label>
          <input id="width-input" type="number" min="0" step="1" disabled />

          <label for="height-input">Height</label>
          <input id="height-input" type="number" min="0" step="1" disabled />

          <label for="lowerChroma-input">Chroma Min</label>
          <input id="lowerChroma-input" type="color" value="#63992E" />

          <label for="upperChroma-input">Chroma Max</label>
          <input id="upperChroma-input" type="color" value="#00FF55" />
        </form>
      </did>
    </div>
    <div class="video-streams" style="background: #d83b9e; padding: 1em">
      <h2>Publishers</h2>
      <div id="publishers"></div>
    </div>
    <div class="video-streams" style="background: #80d0f0; padding: 1em">
      <h2>Subscribers</h2>
      <div id="subscribers"></div>
    </div>

    <script src="https://static.opentok.com/v2/js/opentok.min.js"></script>
    <script>
      /**
       * Convert hexcode color to RGB
       *
       * From https://stackoverflow.com/questions/5623838/rgb-to-hex-and-hex-to-rgb
       */
      const hexToRGB = hex => {
        if (hex[0] == '#') hex = hex.substring(1);
        const bigint = parseInt(hex, 16);
        const r = (bigint >> 16) & 255;
        const g = (bigint >> 8) & 255;
        const b = bigint & 255;

        return [r, g, b];
      }

      const RGBtoHSL = (r, g, b) => {
        r /= 255;
        g /= 255;
        b /= 255;

        const cmin = Math.min(r,g,b);
        const cmax = Math.max(r,g,b);
        let delta = cmax - cmin;

        let [h, s, l] = [0, 0, 0];
        if (delta == 0) h = 0;
        else if (cmax == r) h = ((g - b) / delta) % 6;
        else if (cmax == g) h = (b - r) / delta + 2;
        else h = (r - g) / delta + 4;

        h = Math.round(h * 60);
        if (h < 0) h += 360;
        l = (cmax + cmin) / 2;
        s = delta == 0 ? 0 : delta / (1 - Math.abs(2 * l - 1));
        s = +(s * 100).toFixed(1);
        l = +(l * 100).toFixed(1);

        return [h, s, l];
      }

      const getUserStream = (function setupGreenscreenEvents(){
        const backgroundForm = document.querySelector('#background-image-form');
        const [[ outputCanvas, outputContext ], [ workspaceCanvas, workspaceContext ]] = [...document.querySelectorAll('.processing canvas')].map(canvas => [canvas, canvas.getContext('2d', { alpha: false})]);
        const input = document.querySelector('.processing video');
        let background = {
          x: 0,
          y: 0,
          lowerChroma: [75, 70, 25],
          upperChroma: [180, 100, 75],
          overlay: false,
          image: null
        };
        let frameRate = 60;
        let lastRender = 0;

        /**
         * Set enabled state of background form
         */
        const setFormEnabled = (() => {
          const elements = [...backgroundForm.querySelectorAll('input, button')];
          return (enabled) => elements
            .filter(input => input.id !== 'image-input')
            .forEach(input => input.disabled = !enabled);
        })();

        // Toggle open/closed button text and state
        document.querySelector('.preferences button').addEventListener('click', ({ target }) => {
          const opened = document.querySelector('.preferences .content').classList.toggle('opened');
          target.textValue = opened ? 'Close' : 'Open';
          if (opened) return;

          // Disable overlay when closing
          const overlay = backgroundForm['overlay-input'];
          if (overlay.checked) overlay.click();
        });


        // Remove current background image
        backgroundForm.querySelector('#remove-image').addEventListener('click', () => {
          setFormEnabled(backgroundForm, false);
          background.image = null;
          backgroundForm['image-input'].value = '';
        });

        // Update with new image/options for image
        backgroundForm.addEventListener('change', (e) => {
          const input = e.target;
          const name = input.id.split('-input')[0];

          if (name === 'image') {
              setFormEnabled(backgroundForm, true)
              const imageFile = input.files[0];
              if (!imageFile) return;

              // Convert file to image
              const image = new Image();
              image.onload = () => setBackgroundImage(image);
              image.src = URL.createObjectURL(imageFile);
              return;
          }

          switch(name){
            case 'x':
            case 'y':
            case 'overlay':
              // Post updated preference:
              // value as number for x/y, true/false boolean for overlay
              background = {
                ...background,
                [name]: name === 'overlay' ? input.checked : parseInt(input.value)
              }
              return;
            case 'lowerChroma':
            case 'upperChroma':
              background = {
                ...background,
                [name]: RGBtoHSL(...hexToRGB(input.value))
              }
              return;
            case 'width':
            case 'height':
              // Update the dimensions of the image and update the image data
              background.image[name] = parseInt(input.value);
              return setBackgroundImage(background.image);
          }
        })

        /**
         * Set the background image to use
         */
        const setBackgroundImage = image => {
          // Update form values
          backgroundForm['width-input'].value = image.width;
          backgroundForm['height-input'].value = image.height;

          // Save image for future resolution adjustments
          background.image = image;
        }

        input.addEventListener('play', () => {
          // Update dimensions of canvases and video when video metadata loads
          for (const element of [outputCanvas, workspaceCanvas, input]){
            element.width = input.videoWidth
            element.height = input.videoHeight;
          }

          // Get frame rate and start rendering
          frameRate = input.srcObject.getVideoTracks()[0].getSettings().frameRate;
          render();
        });

        /**
         * Render the current frame of video
         */
        const render = () => {
          // Prevent rendering faster then the frame rate of the input video
          const now = performance.now();
          if (now - lastRender < 1000 / frameRate) return requestAnimationFrame(render);
          lastRender = now;

          // Stop rendering if the video is stopped
          if (input.ended || input.paused) return;

          if (background.image) {
            // Pass frame data to worker
            workspaceContext.drawImage(input, 0, 0);
            outputContext.drawImage(background.image, 0, 0, background.image.width, background.image.height);
            const frame = workspaceContext.getImageData(0, 0, 320, 240)
            const pixels = frame.data;
            for(let i=0; i<pixels.length; i+=4) {
              const [r, g, b] = [pixels[i], pixels[i+1], pixels[i+2]];
              const [h, s, l] = RGBtoHSL(r, g, b);

              // From: https://www.nexmo.com/blog/2020/06/24/use-a-green-screen-in-javascript-with-vonage-video

              // TODO
              // (1) The overlay is not implemented
              // (2) x and y move the origin point but do not also extend the width/height bounds
              // (3) Only pixels under the background image are updated from the video
              //     the rest of the video is static

              // Most is due to the fact we iterate only over the background image - many
              // of these problems only exist due to the fact that the original implmentation
              // iterated over the input video pixels, so iterating over the video pixels
              // and performing the same changes below might be a solution.
              if(h > 110 && h < 200) {
                pixels[i+3] = 0;
              } else {
                outputContext.fillStyle = `rgba(${r}, ${g}, ${b}, 1)`;
                const x = ((i/4) % frame.width) + background.x;
                if (x < 0 || x >= frame.width) continue;

                const y = Math.floor((i / 4) / frame.width) + background.y;
                if (y < 0 || y >= frame.height) continue;
                outputContext.fillRect(x, y, 1, 1);
              }
            }
            frame.data = pixels
          }
          else {
            // There is no background, pass image directly to the output canvas
            outputContext.drawImage(input, 0, 0);
          }

          requestAnimationFrame(render);
        }

        /**
         * Prompt user for video media, and return output canvas
         */
        return async () => {
          const inputStream = await navigator.mediaDevices.getUserMedia({ video: true });
          input.srcObject = inputStream;

          const stream = outputCanvas.captureStream();
          const audioTracks = (input.audioTracks || []);
          if (audioTracks.length) stream.addTrack(audioTracks[0]);
          return stream;
        }
      })();

      getUserStream().then((userStream) => {
        initalizeOpentok(userStream.getVideoTracks()[0], userStream.getAudioTracks()[0]);
      }).catch(err => alert(err));

      const initalizeOpentok = (videoSource, audioSource) => {
        const params = Object.fromEntries(new URLSearchParams(location.search))
        fetch(`/api/session?room=${params.id}`)
          .then(r => r.json())
          .then(({ apiKey, sessionId, token }) => {
            const session = OT.initSession(apiKey, sessionId)
            const camera = OT.initPublisher('publishers', {
              videoSource, audioSource,
              mirror: false
            })
            session.connect(token, () => {
              session.publish(camera)
            })
            session.on('streamCreated', event => {
              console.log('Subscribing!')
              session.subscribe(event.stream, 'subscribers')
            })
          })
      }
    </script>
  </body>
</html>
